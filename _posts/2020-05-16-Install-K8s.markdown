---
layout: post
title:  "Install K8s on Vmware"
date:   2020-05-16 01:34:01 +0700
categories: jekyll update
---
# k8s-install-config

## Package Installation

1. 3 VMs Ubuntu 16.04.5 or 18.04.1.0, 1 master, 2 nodes.
2. Static IPs on individual VMs
3. /etc/hosts hosts file includes name to IP mappings for VMs
4. Swap is disabled
5. Take snapshots prior to installations, this way you can install and revert to snapshot if needed

```properties
# VM Master
network:
    ethernets:
        ens33:
            dhcp4: no
            addresses: [172.16.94.12/24]
            gateway4: 172.16.94.2
            nameservers:
              addresses: [172.16.94.2]
    version: 2
```

```properties
# VM Node1
network:
    ethernets:
        ens33:
            dhcp4: no
            addresses: [172.16.94.13/24]
            gateway4: 172.16.94.2
            nameservers:
              addresses: [172.16.94.2]
    version: 2
```

```properties
# VM Node2
network:
    ethernets:
        ens33:
            dhcp4: no
            addresses: [172.16.94.14/24]
            gateway4: 172.16.94.2
            nameservers:
              addresses: [172.16.94.2]
    version: 2
```

```properties
172.16.94.12 master
172.16.94.13 node1
172.16.94.14 node2
172.16.94.15 node3

```

### Disable swap, swapoff then edit your fstab removing any entry for swap partitions

You can recover the space with fdisk. You may want to reboot to ensure your config is ok.

[Guide removing a Swap File](https://linuxize.com/post/how-to-add-swap-space-on-ubuntu-18-04/#removing-a-swap-file)

```bash
sudo swapon --show
swapoff -a
vi /etc/fstab
  removing swap.img
sudo rm /swap.img
```

REBOOT

### Add Google's apt repository gpg key

```bash
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
```

### Add the Kubernetes apt repository

```bash
sudo bash -c 'cat <<EOF >/etc/apt/sources.list.d/kubernetes.list
deb https://apt.kubernetes.io/ kubernetes-xenial main
EOF'
```

### Update the package list and use apt-cache to inspect versions available in the repository

```bash
sudo apt-get update
apt-cache policy kubelet | head -n 20
apt-cache policy docker.io | head -n 20
```

### Install the required packages, if needed we can request a specific version

```bash
sudo apt-get install -y docker.io kubelet kubeadm kubectl
sudo apt-mark hold docker.io kubelet kubeadm kubectl
```

### Check the status of our kubelet and our container runtime, docker

The kubelet will enter a crashloop until it's joined.

```bash
sudo systemctl status kubelet.service
sudo systemctl status docker.service
```

### Ensure both are set to start when the system starts up

```bash
sudo systemctl enable kubelet.service
sudo systemctl enable docker.service
```

### Setup Docker daemon. This a change that has been added since the recording of the course

```bash
sudo bash -c 'cat > /etc/docker/daemon.json <<EOF
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2"
}
EOF'
```

### Restart reload the systemd config and docker

```bash
sudo systemctl daemon-reload
sudo systemctl restart docker
```

## Create Master

## Only on the master, download the yaml files for the pod network

The calico yaml file has changed since the publication of the course and is now avaialble at the URL below.

```bash
wget https://docs.projectcalico.org/manifests/calico.yaml
```

### Look inside calico.yaml and find the network range CALICO_IPV4POOL_CIDR, adjust if needed

vi calico.yaml

### Search and unblock CALICO_IPV4POOL_CIDR

```bash
            - name: CALICO_IPV4POOL_CIDR
              value: "192.168.0.0/16"
```

### Create our kubernetes cluster, specifying a pod network range matching that in calico.yaml

sudo kubeadm init --pod-network-cidr=192.168.0.0/16

### Configure our account on the master to have admin access to the API server from a non-privileged account

mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

### Deploy yaml file for your pod network

This line of code has be updated since the publication of the course.

kubectl apply -f calico.yaml

### Look for the all the system pods and calico pod to change to Running

The DNS pod won't start until the Pod network is deployed and Running.

```bash
kubectl get pods --all-namespaces
```

### Gives you output over time, rather than repainting the screen on each iteration

kubectl get pods --all-namespaces --watch

### All system pods should be Running

kubectl get pods --all-namespaces

### Get a list of our current nodes, just the master

kubectl get nodes

### Check out the systemd unit, and examine 10-kubeadm.conf

Remeber the kubelet starts static pod manifests, and thus the core cluster pods

```bash
sudo systemctl status kubelet.service
```

### check out the directory where the kubeconfig files live

ls /etc/kubernetes

### let's check out the manifests on the master

ls /etc/kubernetes/manifests

### And look more closely at API server and etcd's manifest

```bash
sudo more /etc/kubernetes/manifests/etcd.yaml
sudo more /etc/kubernetes/manifests/kube-apiserver.yaml
```
